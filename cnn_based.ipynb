{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5af5a7-fb16-4003-972c-b6f7d6196f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_channels=2):\n",
    "        super().__init__()\n",
    "        # First conv: 65x65 -> 22x22\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=7, stride=3, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        # Second conv: 22x22 -> 8x8\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=3, padding=2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Final conv: maintain 8x8 but process features\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.repr_dim = 32\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # -> 22x22\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # -> 8x8\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # -> 8x8\n",
    "        return x  # Output shape: [B, 32, 8, 8]\n",
    "\n",
    "class TransitionModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Action embedding\n",
    "        self.action_embed = nn.Sequential(\n",
    "            nn.Conv2d(2, 16, 1),  # First go to intermediate dimension\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, hidden_dim, 1),  # Then to full hidden_dim\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Transition model\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim * 2, hidden_dim, 3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state: [B, hidden_dim, 8, 8] - Current state representation\n",
    "            action: [B, 2] - (dx, dy) action\n",
    "        \"\"\"\n",
    "        B, _, H, W = state.shape\n",
    "        \n",
    "        # Expand action to spatial dimensions and embed\n",
    "        action = action.view(B, 2, 1, 1).expand(-1, -1, H, W)\n",
    "        action_embedding = self.action_embed(action)\n",
    "        \n",
    "        # Combine state and action\n",
    "        combined = torch.cat([state, action_embedding], dim=1)\n",
    "        \n",
    "        # Predict state change\n",
    "        delta = self.transition(combined)\n",
    "        \n",
    "        # Residual connection\n",
    "        next_state = state + delta\n",
    "        \n",
    "        return next_state\n",
    "\n",
    "class WorldModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_channels=2)\n",
    "        self.predictor = TransitionModel(hidden_dim=32)\n",
    "        \n",
    "    def forward(self, states, actions):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            states: [B, 1, 2, 65, 65] - Initial state only\n",
    "            actions: [B, T-1, 2] - Sequence of T-1 actions\n",
    "        Returns:\n",
    "            predictions: [B, T, 32, 8, 8] - Predicted representations\n",
    "        \"\"\"\n",
    "        B, _, _, H, W = states.shape\n",
    "        T = actions.shape[1] + 1\n",
    "        \n",
    "        # Get initial state encoding\n",
    "        curr_state = self.encoder(states.squeeze(1))\n",
    "        predictions = [curr_state]\n",
    "        \n",
    "        # Predict future states\n",
    "        for t in range(T-1):\n",
    "            curr_state = self.predictor(curr_state, actions[:, t])\n",
    "            predictions.append(curr_state)\n",
    "            \n",
    "        predictions = torch.stack(predictions, dim=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e954244-00c2-4c71-9ad6-18f5c58d7d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model tests with real data...\n",
      "\n",
      "Input Data Shapes:\n",
      "States shape: torch.Size([256, 17, 2, 65, 65])\n",
      "Actions shape: torch.Size([256, 16, 2])\n",
      "States min/max: 0.00, 0.09\n",
      "Actions min/max: -1.78, 1.79\n",
      "\n",
      "Encoder output shape: torch.Size([256, 32, 8, 8])\n",
      "\n",
      "Single action sample:\n",
      "Action values: tensor([-0.4640, -0.6881], device='cuda:0')\n",
      "\n",
      "Action processing:\n",
      "Action after spatial expansion: torch.Size([256, 2, 8, 8])\n",
      "Action after embedding: torch.Size([256, 32, 8, 8])\n",
      "\n",
      "Prediction shapes:\n",
      "Single step prediction: torch.Size([256, 32, 8, 8])\n",
      "Full sequence prediction: torch.Size([256, 17, 32, 8, 8])\n",
      "\n",
      "Compression Statistics:\n",
      "Input size per frame: 8450 values\n",
      "Encoded size per frame: 2048 values\n",
      "Compression ratio: 4.13x\n",
      "\n",
      "All dimension tests passed!\n",
      "\n",
      "Testing multiple forward passes...\n",
      "Batch 1 processed successfully.\n",
      "Prediction stats for batch 1:\n",
      "Mean: 0.391\n",
      "Std: 7.903\n",
      "Min: -94.089\n",
      "Max: 98.552\n",
      "Batch 2 processed successfully.\n",
      "Batch 3 processed successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dataset import create_wall_dataloader\n",
    "\n",
    "def test_model_with_real_data():\n",
    "    # Initialize models with new dimensions\n",
    "    encoder = Encoder(input_channels=2).to('cuda')\n",
    "    predictor = TransitionModel(hidden_dim=32).to('cuda')\n",
    "    world_model = WorldModel().to('cuda')\n",
    "    \n",
    "    # Create data loader with actual data\n",
    "    data_path = \"/drive_reader/as16386/DL24FA/train\"\n",
    "    dataloader = create_wall_dataloader(\n",
    "        data_path=data_path,\n",
    "        probing=False,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        batch_size=256,\n",
    "        train=True\n",
    "    )\n",
    "    \n",
    "    # Get a batch of data\n",
    "    batch = next(iter(dataloader))\n",
    "    states = batch.states  # [B, T, C, H, W]\n",
    "    actions = batch.actions  # [B, T-1, 2]\n",
    "    \n",
    "    print(\"\\nInput Data Shapes:\")\n",
    "    print(f\"States shape: {states.shape}\")  # Should be [4, T, 2, 65, 65]\n",
    "    print(f\"Actions shape: {actions.shape}\")  # Should be [4, T-1, 2]\n",
    "    print(f\"States min/max: {states.min():.2f}, {states.max():.2f}\")\n",
    "    print(f\"Actions min/max: {actions.min():.2f}, {actions.max():.2f}\")\n",
    "    \n",
    "    # Test encoder with initial state\n",
    "    init_state = states[:, 0]  # Take first timestep\n",
    "    encoded = encoder(init_state)\n",
    "    print(f\"\\nEncoder output shape: {encoded.shape}\")  # Should be [4, 32, 8, 8]\n",
    "    \n",
    "    # Test predictor with a single action\n",
    "    single_action = actions[:, 0]  # Take first action\n",
    "    print(f\"\\nSingle action sample:\")\n",
    "    print(f\"Action values: {single_action[0]}\")  # Print first batch's action\n",
    "    \n",
    "    # Test action processing\n",
    "    B, _, h, w = encoded.shape\n",
    "    action_spatial = single_action.view(B, 2, 1, 1).expand(-1, -1, h, w)\n",
    "    print(f\"\\nAction processing:\")\n",
    "    print(f\"Action after spatial expansion: {action_spatial.shape}\")  # Should be [4, 2, 8, 8]\n",
    "    \n",
    "    # Test action embedding\n",
    "    action_embedded = predictor.action_embed(action_spatial)\n",
    "    print(f\"Action after embedding: {action_embedded.shape}\")  # Should be [4, 32, 8, 8]\n",
    "    \n",
    "    # Test single prediction step\n",
    "    next_state = predictor(encoded, single_action)\n",
    "    print(f\"\\nPrediction shapes:\")\n",
    "    print(f\"Single step prediction: {next_state.shape}\")  # Should be [4, 32, 8, 8]\n",
    "    \n",
    "    # Test full sequence prediction\n",
    "    init_states = states[:, 0:1]  # [B, 1, C, H, W]\n",
    "    sequence_actions = actions  # [B, T-1, 2]\n",
    "    predictions = world_model(init_states, sequence_actions)\n",
    "    print(f\"Full sequence prediction: {predictions.shape}\")\n",
    "    # Should be [B, T, 32, 8, 8]\n",
    "    \n",
    "    # Print compression stats\n",
    "    input_size = states.shape[-2] * states.shape[-1] * states.shape[-3]\n",
    "    encoded_size = encoded.shape[-2] * encoded.shape[-1] * encoded.shape[-3]\n",
    "    compression_ratio = input_size / encoded_size\n",
    "    print(f\"\\nCompression Statistics:\")\n",
    "    print(f\"Input size per frame: {input_size} values\")\n",
    "    print(f\"Encoded size per frame: {encoded_size} values\")\n",
    "    print(f\"Compression ratio: {compression_ratio:.2f}x\")\n",
    "    \n",
    "    # Verify shapes\n",
    "    assert encoded.shape[1] == 32, \"Channel dimension mismatch\"\n",
    "    assert encoded.shape[2] == encoded.shape[3] == 8, \"Spatial dimensions mismatch\"\n",
    "    assert predictions.shape[1] == actions.shape[1] + 1, \"Sequence length mismatch\"\n",
    "    assert predictions.shape[2] == 32, \"Output channel mismatch\"\n",
    "    assert predictions.shape[3] == predictions.shape[4] == 8, \"Output spatial dimension mismatch\"\n",
    "    \n",
    "    print(\"\\nAll dimension tests passed!\")\n",
    "    \n",
    "    # Test multiple forward passes\n",
    "    print(\"\\nTesting multiple forward passes...\")\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i >= 3:  # Test with 3 batches\n",
    "            break\n",
    "        states = batch.states\n",
    "        actions = batch.actions\n",
    "        init_states = states[:, 0:1]\n",
    "        with torch.no_grad():\n",
    "            predictions = world_model(init_states, actions)\n",
    "        print(f\"Batch {i+1} processed successfully.\")\n",
    "        \n",
    "        # Print some statistics about the predictions\n",
    "        if i == 0:\n",
    "            print(f\"Prediction stats for batch {i+1}:\")\n",
    "            print(f\"Mean: {predictions.mean():.3f}\")\n",
    "            print(f\"Std: {predictions.std():.3f}\")\n",
    "            print(f\"Min: {predictions.min():.3f}\")\n",
    "            print(f\"Max: {predictions.max():.3f}\")\n",
    "    \n",
    "    return world_model, dataloader\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running model tests with real data...\")\n",
    "    model, dataloader = test_model_with_real_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c757cde1-d5d0-4a18-8c98-384222893a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from dataset import WallSample\n",
    "\n",
    "class VICRegLoss(nn.Module):\n",
    "    def __init__(self, lambda_param=25.0, mu_param=25.0, nu_param=1.0):\n",
    "        super().__init__()\n",
    "        self.lambda_param = lambda_param  # invariance loss coefficient\n",
    "        self.mu_param = mu_param         # variance loss coefficient\n",
    "        self.nu_param = nu_param         # covariance loss coefficient\n",
    "    \n",
    "    def off_diagonal(self, x):\n",
    "        \"\"\"Return off-diagonal elements of a square matrix\"\"\"\n",
    "        n = x.shape[0]\n",
    "        return x.flatten()[:-1].view(n-1, n+1)[:, 1:].flatten()\n",
    "    \n",
    "    def forward(self, z_a, z_b):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z_a, z_b: Batch of representations [N, D]\n",
    "        Returns:\n",
    "            total_loss: Combined VICReg loss\n",
    "            losses: Dictionary containing individual loss components\n",
    "        \"\"\"\n",
    "        N = z_a.shape[0]  # batch size\n",
    "        D = z_a.shape[1]  # dimension\n",
    "        \n",
    "        # Invariance loss (MSE)\n",
    "        sim_loss = F.mse_loss(z_a, z_b)\n",
    "        \n",
    "        # Variance loss\n",
    "        std_z_a = torch.sqrt(z_a.var(dim=0) + 1e-04)\n",
    "        std_z_b = torch.sqrt(z_b.var(dim=0) + 1e-04)\n",
    "        std_loss = (torch.mean(F.relu(1 - std_z_a)) + \n",
    "                   torch.mean(F.relu(1 - std_z_b)))\n",
    "        \n",
    "        # Covariance loss\n",
    "        z_a = z_a - z_a.mean(dim=0)\n",
    "        z_b = z_b - z_b.mean(dim=0)\n",
    "        \n",
    "        cov_z_a = (z_a.T @ z_a) / (N - 1)\n",
    "        cov_z_b = (z_b.T @ z_b) / (N - 1)\n",
    "        \n",
    "        cov_loss = (self.off_diagonal(cov_z_a).pow_(2).sum() / D +\n",
    "                   self.off_diagonal(cov_z_b).pow_(2).sum() / D)\n",
    "        \n",
    "        # Combine losses\n",
    "        total_loss = (self.lambda_param * sim_loss + \n",
    "                     self.mu_param * std_loss + \n",
    "                     self.nu_param * cov_loss)\n",
    "        \n",
    "        # Return individual losses for logging\n",
    "        losses = {\n",
    "            'sim_loss': sim_loss.item(),\n",
    "            'std_loss': std_loss.item(),\n",
    "            'cov_loss': cov_loss.item(),\n",
    "            'total_loss': total_loss.item()\n",
    "        }\n",
    "        \n",
    "        return total_loss, losses\n",
    "\n",
    "class WorldModelVICReg(nn.Module):\n",
    "    def __init__(self, lambda_param=25.0, mu_param=25.0, nu_param=1.0):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_channels=2)\n",
    "        self.predictor = TransitionModel(hidden_dim=32)\n",
    "        self.criterion = VICRegLoss(lambda_param, mu_param, nu_param)\n",
    "        self.repr_dim = 32 * 8 * 8\n",
    "    \n",
    "    def compute_vicreg_loss(self, pred_state, target_obs):\n",
    "        \"\"\"Compute VICReg loss between predicted and encoded target states\"\"\"\n",
    "        # Get target encoding\n",
    "        target_state = self.encoder(target_obs)\n",
    "        \n",
    "        # Flatten spatial dimensions: [B, 32, 8, 8] -> [B, 2048]\n",
    "        pred_flat = pred_state.flatten(start_dim=1)\n",
    "        target_flat = target_state.flatten(start_dim=1)\n",
    "        \n",
    "        # Compute VICReg losses\n",
    "        total_loss, component_losses = self.criterion(pred_flat, target_flat)\n",
    "        return total_loss, component_losses\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        states = batch.states\n",
    "        actions = batch.actions\n",
    "        \n",
    "        # Get initial state\n",
    "        init_states = states[:, 0:1]\n",
    "        \n",
    "        # Get predictions for all steps\n",
    "        predictions = self.forward_prediction(init_states, actions)\n",
    "        \n",
    "        # Initialize losses\n",
    "        total_loss = 0.0\n",
    "        accumulated_losses = {\n",
    "            'sim_loss': 0.0,\n",
    "            'std_loss': 0.0,\n",
    "            'cov_loss': 0.0,\n",
    "            'total_loss': 0.0\n",
    "        }\n",
    "        \n",
    "        # Compute VICReg loss for each timestep\n",
    "        for t in range(actions.shape[1]):\n",
    "            pred_state = predictions[:, t+1]\n",
    "            target_obs = states[:, t+1]\n",
    "            \n",
    "            loss, component_losses = self.compute_vicreg_loss(pred_state, target_obs)\n",
    "            total_loss += loss\n",
    "            \n",
    "            # Accumulate component losses\n",
    "            for k in accumulated_losses:\n",
    "                accumulated_losses[k] += component_losses[k]\n",
    "        \n",
    "        # Average losses over timesteps\n",
    "        for k in accumulated_losses:\n",
    "            accumulated_losses[k] /= actions.shape[1]\n",
    "        \n",
    "        return total_loss / actions.shape[1], predictions, accumulated_losses\n",
    "\n",
    "\n",
    "    def forward_prediction(self, states, actions):\n",
    "        \"\"\"\n",
    "        Forward pass for prediction of future states\n",
    "        Args:\n",
    "            states: [B, 1, 2, 65, 65] - Initial state only\n",
    "            actions: [B, T-1, 2] - Sequence of T-1 actions\n",
    "        Returns:\n",
    "            predictions: [B, T, 32, 8, 8] - Predicted representations\n",
    "        \"\"\"\n",
    "        B, _, _, H, W = states.shape\n",
    "        T = actions.shape[1] + 1\n",
    "        \n",
    "        # Get initial state encoding\n",
    "        curr_state = self.encoder(states.squeeze(1))\n",
    "        predictions = [curr_state]\n",
    "        \n",
    "        # Predict future states\n",
    "        for t in range(T-1):\n",
    "            curr_state = self.predictor(curr_state, actions[:, t])\n",
    "            predictions.append(curr_state)\n",
    "            \n",
    "        predictions = torch.stack(predictions, dim=1)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb94ac6-04ce-449e-9ff8-530b0c297049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "class WorldModelTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, learning_rate=1e-3, \n",
    "                 device='cuda', log_dir='runs'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Initialize tensorboard writer\n",
    "        current_time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        self.writer = SummaryWriter(f'{log_dir}/{current_time}')\n",
    "        \n",
    "        # Save hyperparameters\n",
    "        self.writer.add_text('hyperparameters', f'''\n",
    "        learning_rate: {learning_rate}\n",
    "        batch_size: {train_loader.batch_size}\n",
    "        model_channels: {model.encoder.repr_dim}\n",
    "        ''')\n",
    "\n",
    "    def validate(self, epoch):\n",
    "        self.model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        val_losses = {\n",
    "            'total_loss': 0.0,\n",
    "            'sim_loss': 0.0,\n",
    "            'std_loss': 0.0,\n",
    "            'cov_loss': 0.0\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                states = batch.states.to(self.device)\n",
    "                actions = batch.actions.to(self.device)\n",
    "                \n",
    "                loss, _, component_losses = self.model.training_step(\n",
    "                    WallSample(states=states, actions=actions, locations=batch.locations)\n",
    "                )\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "                for k in val_losses:\n",
    "                    val_losses[k] += component_losses[k]\n",
    "        \n",
    "        # Average the losses\n",
    "        num_batches = len(self.val_loader)\n",
    "        total_val_loss /= num_batches\n",
    "        for k in val_losses:\n",
    "            val_losses[k] /= num_batches\n",
    "            \n",
    "        return total_val_loss, val_losses\n",
    "\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        total_train_loss = 0.0  # Changed variable name for clarity\n",
    "        train_losses = {\n",
    "            'total_loss': 0.0,\n",
    "            'sim_loss': 0.0,\n",
    "            'std_loss': 0.0,\n",
    "            'cov_loss': 0.0\n",
    "        }\n",
    "        \n",
    "        for batch_idx, batch in enumerate(tqdm(self.train_loader, desc=f\"Epoch {epoch}\")):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            states = batch.states.to(self.device)\n",
    "            actions = batch.actions.to(self.device)\n",
    "            \n",
    "            loss, _, component_losses = self.model.training_step(\n",
    "                WallSample(states=states, actions=actions, locations=batch.locations)\n",
    "            )\n",
    "            \n",
    "            # Add backpropagation steps\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Update running losses\n",
    "            total_train_loss += loss.item()\n",
    "            for k in train_losses:\n",
    "                train_losses[k] += component_losses[k]\n",
    "        \n",
    "        # Average the losses\n",
    "        num_batches = len(self.train_loader)\n",
    "        total_train_loss /= num_batches\n",
    "        for k in train_losses:\n",
    "            train_losses[k] /= num_batches\n",
    "            \n",
    "        return total_train_loss, train_losses  # Return both total loss and component losses\n",
    "\n",
    "    \n",
    "    def save_checkpoint(self, epoch, loss):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }\n",
    "        path = f'checkpoints/checkpoint_epoch_{epoch}.pt'\n",
    "        os.makedirs('checkpoints', exist_ok=True)\n",
    "        torch.save(checkpoint, path)\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_losses = self.train_epoch(epoch)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_losses = self.validate(epoch)\n",
    "            \n",
    "            # Print epoch summary\n",
    "            print(\"\\nEpoch Summary:\")\n",
    "            print(\"Training Losses:\")\n",
    "            for k, v in train_losses.items():\n",
    "                print(f\"{k}: {v:.4f}\")\n",
    "            print(\"\\nValidation Losses:\")\n",
    "            for k, v in val_losses.items():\n",
    "                print(f\"{k}: {v:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                self.save_checkpoint(epoch, val_loss)\n",
    "                print(\"New best model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11dc2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_loaders(data_path, train_samples=10000, val_samples=2000):\n",
    "    \"\"\"Helper function to create train and validation loaders\"\"\"\n",
    "    train_loader = create_wall_dataloader(\n",
    "        data_path=data_path,\n",
    "        probing=False,\n",
    "        device=\"cuda\",\n",
    "        batch_size=128,\n",
    "        train=True,\n",
    "        num_samples=train_samples\n",
    "    )\n",
    "    \n",
    "    val_loader = create_wall_dataloader(\n",
    "        data_path=data_path,\n",
    "        probing=False,\n",
    "        device=\"cuda\",\n",
    "        batch_size=128,\n",
    "        train=False,\n",
    "        num_samples=val_samples\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc9ae01-d991-481b-b466-8352253dbbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1148/1148 [01:16<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 658.3185\n",
      "sim_loss: 1.4807\n",
      "std_loss: 0.8522\n",
      "cov_loss: 599.9961\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 26.8438\n",
      "sim_loss: 0.0232\n",
      "std_loss: 0.7444\n",
      "cov_loss: 7.6523\n",
      "New best model saved!\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1148/1148 [01:13<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 26.2803\n",
      "sim_loss: 0.0142\n",
      "std_loss: 0.7292\n",
      "cov_loss: 7.6959\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 25.9647\n",
      "sim_loss: 0.0089\n",
      "std_loss: 0.7398\n",
      "cov_loss: 7.2476\n",
      "New best model saved!\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1148/1148 [01:13<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 25.7677\n",
      "sim_loss: 0.0088\n",
      "std_loss: 0.7041\n",
      "cov_loss: 7.9432\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 25.7630\n",
      "sim_loss: 0.0080\n",
      "std_loss: 0.7251\n",
      "cov_loss: 7.4357\n",
      "New best model saved!\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1148/1148 [01:14<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 25.5915\n",
      "sim_loss: 0.0084\n",
      "std_loss: 0.6935\n",
      "cov_loss: 8.0417\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 25.5491\n",
      "sim_loss: 0.0082\n",
      "std_loss: 0.6686\n",
      "cov_loss: 8.6282\n",
      "New best model saved!\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1148/1148 [01:13<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 25.4702\n",
      "sim_loss: 0.0083\n",
      "std_loss: 0.6863\n",
      "cov_loss: 8.1050\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 25.4718\n",
      "sim_loss: 0.0078\n",
      "std_loss: 0.6622\n",
      "cov_loss: 8.7236\n",
      "New best model saved!\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1148/1148 [01:13<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 25.3877\n",
      "sim_loss: 0.0085\n",
      "std_loss: 0.6815\n",
      "cov_loss: 8.1373\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 25.3748\n",
      "sim_loss: 0.0088\n",
      "std_loss: 0.6983\n",
      "cov_loss: 7.6964\n",
      "New best model saved!\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1148/1148 [01:13<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 25.3003\n",
      "sim_loss: 0.0087\n",
      "std_loss: 0.6764\n",
      "cov_loss: 8.1741\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 25.2971\n",
      "sim_loss: 0.0084\n",
      "std_loss: 0.6654\n",
      "cov_loss: 8.4525\n",
      "New best model saved!\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1148/1148 [01:13<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 25.2213\n",
      "sim_loss: 0.0083\n",
      "std_loss: 0.6723\n",
      "cov_loss: 8.2079\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 25.2043\n",
      "sim_loss: 0.0080\n",
      "std_loss: 0.6622\n",
      "cov_loss: 8.4495\n",
      "New best model saved!\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1148/1148 [01:14<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 25.1733\n",
      "sim_loss: 0.0080\n",
      "std_loss: 0.6696\n",
      "cov_loss: 8.2325\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 25.1729\n",
      "sim_loss: 0.0078\n",
      "std_loss: 0.6702\n",
      "cov_loss: 8.2235\n",
      "New best model saved!\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1148/1148 [01:14<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 25.1431\n",
      "sim_loss: 0.0080\n",
      "std_loss: 0.6679\n",
      "cov_loss: 8.2476\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 25.1438\n",
      "sim_loss: 0.0081\n",
      "std_loss: 0.6642\n",
      "cov_loss: 8.3363\n",
      "New best model saved!\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1148/1148 [01:13<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Summary:\n",
      "Training Losses:\n",
      "total_loss: 25.1245\n",
      "sim_loss: 0.0079\n",
      "std_loss: 0.6671\n",
      "cov_loss: 8.2514\n",
      "\n",
      "Validation Losses:\n",
      "total_loss: 25.1182\n",
      "sim_loss: 0.0067\n",
      "std_loss: 0.6683\n",
      "cov_loss: 8.2425\n",
      "New best model saved!\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:  23%|██▎       | 261/1148 [00:16<00:57, 15.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize trainer and train\u001b[39;00m\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m WorldModelTrainer(model, train_loader, val_loader)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 114\u001b[0m, in \u001b[0;36mWorldModelTrainer.train\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m train_loss, train_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m    117\u001b[0m val_loss, val_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(epoch)\n",
      "Cell \u001b[0;32mIn[7], line 82\u001b[0m, in \u001b[0;36mWorldModelTrainer.train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Update running losses\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m train_losses:\n\u001b[1;32m     84\u001b[0m     train_losses[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m component_losses[k]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize model and dataloaders\n",
    "model = WorldModelVICReg(\n",
    "    lambda_param=25.0,\n",
    "    mu_param=25.0,\n",
    "    nu_param=1.0\n",
    ")\n",
    "\n",
    "train_loader, val_loader = create_train_val_loaders(\n",
    "    data_path=\"/drive_reader/as16386/DL24FA/train\",\n",
    "    train_samples=None,\n",
    "    val_samples=None\n",
    ")\n",
    "\n",
    "# Initialize trainer and train\n",
    "trainer = WorldModelTrainer(model, train_loader, val_loader)\n",
    "trainer.train(num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a9bd16-8568-4df4-ae39-f0684b2ba38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_252118/4229374378.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('checkpoints/checkpoint_epoch_10.pt')['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WorldModelVICReg().to('cuda')\n",
    "model.load_state_dict(torch.load('checkpoints/checkpoint_epoch_10.pt')['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b88292c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/drive_reader/as16386/DL-final-proj/dl_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset import create_wall_dataloader\n",
    "from evaluator import ProbingEvaluator\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Check for GPU availability.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    return device\n",
    "\n",
    "\n",
    "def load_data(device):\n",
    "    data_path = \"/drive_reader/as16386/DL24FA\"\n",
    "\n",
    "    probe_train_ds = create_wall_dataloader(\n",
    "        data_path=f\"{data_path}/probe_normal/train\",\n",
    "        probing=True,\n",
    "        device=device,\n",
    "        train=True,\n",
    "    )\n",
    "\n",
    "    probe_val_normal_ds = create_wall_dataloader(\n",
    "        data_path=f\"{data_path}/probe_normal/val\",\n",
    "        probing=True,\n",
    "        device=device,\n",
    "        train=False,\n",
    "    )\n",
    "\n",
    "    probe_val_wall_ds = create_wall_dataloader(\n",
    "        data_path=f\"{data_path}/probe_wall/val\",\n",
    "        probing=True,\n",
    "        device=device,\n",
    "        train=False,\n",
    "    )\n",
    "\n",
    "    probe_val_ds = {\"normal\": probe_val_normal_ds, \"wall\": probe_val_wall_ds}\n",
    "\n",
    "    return probe_train_ds, probe_val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a8d13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(device, model, probe_train_ds, probe_val_ds):\n",
    "    evaluator = ProbingEvaluator(\n",
    "        device=device,\n",
    "        model=model,\n",
    "        probe_train_ds=probe_train_ds,\n",
    "        probe_val_ds=probe_val_ds,\n",
    "        quick_debug=False,\n",
    "    )\n",
    "\n",
    "    prober = evaluator.train_pred_prober()\n",
    "\n",
    "    avg_losses = evaluator.evaluate_all(prober=prober)\n",
    "\n",
    "    for probe_attr, loss in avg_losses.items():\n",
    "        print(f\"{probe_attr} loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21612662",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "probe_train_ds, probe_val_ds = load_data(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7889eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction epochs:   0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 1.2220221757888794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step:   8%|▊         | 13/156 [00:00<00:02, 58.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.9456378817558289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 60.22it/s]\n",
      "Probe prediction epochs:   5%|▌         | 1/20 [00:02<00:49,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.7320659756660461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 64.79it/s]\n",
      "Probe prediction epochs:  10%|█         | 2/20 [00:05<00:44,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.6127805113792419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.502149224281311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 65.82it/s]\n",
      "Probe prediction epochs:  15%|█▌        | 3/20 [00:07<00:41,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.40175843238830566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.41368675231933594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 65.31it/s]\n",
      "Probe prediction epochs:  20%|██        | 4/20 [00:09<00:38,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.3277325928211212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 66.31it/s]\n",
      "Probe prediction epochs:  25%|██▌       | 5/20 [00:12<00:35,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.2734801471233368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.2918351888656616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 66.27it/s]\n",
      "Probe prediction epochs:  30%|███       | 6/20 [00:14<00:33,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.2518813908100128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 66.56it/s]\n",
      "Probe prediction epochs:  35%|███▌      | 7/20 [00:16<00:30,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.27193519473075867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.2786939740180969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 65.45it/s]\n",
      "Probe prediction epochs:  40%|████      | 8/20 [00:19<00:28,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.290689080953598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 66.42it/s]\n",
      "Probe prediction epochs:  45%|████▌     | 9/20 [00:21<00:26,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.30876070261001587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.2520163059234619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 68.42it/s]\n",
      "Probe prediction epochs:  50%|█████     | 10/20 [00:23<00:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.31273388862609863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.3711901605129242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 67.42it/s]\n",
      "Probe prediction epochs:  55%|█████▌    | 11/20 [00:26<00:20,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.29911911487579346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 67.84it/s]\n",
      "Probe prediction epochs:  60%|██████    | 12/20 [00:28<00:18,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.1957467943429947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.34683114290237427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 67.30it/s]\n",
      "Probe prediction epochs:  65%|██████▌   | 13/20 [00:30<00:16,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.22055520117282867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 66.43it/s]\n",
      "Probe prediction epochs:  70%|███████   | 14/20 [00:33<00:13,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.25660833716392517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.30981215834617615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 66.01it/s]\n",
      "Probe prediction epochs:  75%|███████▌  | 15/20 [00:35<00:11,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.2299424707889557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 65.05it/s]\n",
      "Probe prediction epochs:  80%|████████  | 16/20 [00:37<00:09,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.2722468078136444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.2655680477619171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 65.18it/s]\n",
      "Probe prediction epochs:  85%|████████▌ | 17/20 [00:40<00:07,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.18992485105991364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 64.85it/s]\n",
      "Probe prediction epochs:  90%|█████████ | 18/20 [00:42<00:04,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.33000239729881287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.17655614018440247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 64.96it/s]\n",
      "Probe prediction epochs:  95%|█████████▌| 19/20 [00:45<00:02,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.24664466083049774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 0.23373831808567047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probe prediction step: 100%|██████████| 156/156 [00:02<00:00, 66.63it/s]\n",
      "Probe prediction epochs: 100%|██████████| 20/20 [00:47<00:00,  2.37s/it]\n",
      "Eval probe pred: 100%|██████████| 62/62 [00:00<00:00, 74.46it/s]\n",
      "Eval probe pred: 100%|██████████| 62/62 [00:00<00:00, 74.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal loss: 73.55511474609375\n",
      "wall loss: 131.4816436767578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(device, model, probe_train_ds, probe_val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59448f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
