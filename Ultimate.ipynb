{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14271b34-840c-40e9-814e-f797194a731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, Dict\n",
    "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
    "from lightly.utils.scheduler import cosine_schedule\n",
    "from dataset import create_wall_dataloader\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "INPUT_SHAPE = (2, 65, 65)  # 2 channel 65x65 images\n",
    "ACTION_DIM = 2\n",
    "STATE_DIM = 256  # Encoded state dimension\n",
    "HIDDEN_DIM = 600  # GRU hidden dimension\n",
    "BATCH_SIZE = 32\n",
    "MOMENTUM = 0.996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31501042-a56b-4bd6-8876-573d730294ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_wall_dataloader(\n",
    "    \"/scratch/an3854/DL24FA/train\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train=True, \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea58d5a-f338-477d-9273-605a95e74216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch type: <class 'dataset.WallSample'>\n",
      "\n",
      "Batch is a named tuple with fields: ('states', 'locations', 'actions')\n",
      "\n",
      "States tensor:\n",
      "- Shape: torch.Size([32, 17, 2, 65, 65])\n",
      "- Type: torch.float32\n",
      "- Device: cuda:0\n",
      "\n",
      "Actions tensor:\n",
      "- Shape: torch.Size([32, 16, 2])\n",
      "- Type: torch.float32\n",
      "- Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Get one batch from the dataloader\n",
    "train_iter = iter(train_loader)\n",
    "batch = next(train_iter)\n",
    "\n",
    "# Print batch type and contents\n",
    "print(\"Batch type:\", type(batch))\n",
    "print(\"\\nBatch is a named tuple with fields:\", batch._fields)\n",
    "\n",
    "print(\"\\nStates tensor:\")\n",
    "print(\"- Shape:\", batch.states.shape)\n",
    "print(\"- Type:\", batch.states.dtype)\n",
    "print(\"- Device:\", batch.states.device)\n",
    "\n",
    "print(\"\\nActions tensor:\")\n",
    "print(\"- Shape:\", batch.actions.shape)\n",
    "print(\"- Type:\", batch.actions.dtype)\n",
    "print(\"- Device:\", batch.actions.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaaa2d0-a176-4115-8189-4570e70d60be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b72ec32e-1eef-4797-b416-bec5ee6f0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBE\n",
    "from dataset import create_wall_dataloader\n",
    "from evaluator import ProbingEvaluator\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Check for GPU availability.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    return device\n",
    "\n",
    "\n",
    "def load_data(device):\n",
    "    data_path = \"/scratch/an3854/DL24FA\"\n",
    "\n",
    "    probe_train_ds = create_wall_dataloader(\n",
    "        data_path=f\"{data_path}/probe_normal/train\",\n",
    "        probing=True,\n",
    "        device=device,\n",
    "        train=True,\n",
    "    )\n",
    "\n",
    "    probe_val_normal_ds = create_wall_dataloader(\n",
    "        data_path=f\"{data_path}/probe_normal/val\",\n",
    "        probing=True,\n",
    "        device=device,\n",
    "        train=False,\n",
    "    )\n",
    "\n",
    "    probe_val_wall_ds = create_wall_dataloader(\n",
    "        data_path=f\"{data_path}/probe_wall/val\",\n",
    "        probing=True,\n",
    "        device=device,\n",
    "        train=False,\n",
    "    )\n",
    "\n",
    "    probe_val_ds = {\"normal\": probe_val_normal_ds, \"wall\": probe_val_wall_ds}\n",
    "\n",
    "    return probe_train_ds, probe_val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cb62c5f-febb-4243-a399-eb52c2ae6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(device, model, probe_train_ds, probe_val_ds):\n",
    "    evaluator = ProbingEvaluator(\n",
    "        device=device,\n",
    "        model=model,\n",
    "        probe_train_ds=probe_train_ds,\n",
    "        probe_val_ds=probe_val_ds,\n",
    "        quick_debug=False,\n",
    "    )\n",
    "\n",
    "    prober = evaluator.train_pred_prober()\n",
    "\n",
    "    avg_losses = evaluator.evaluate_all(prober=prober)\n",
    "\n",
    "    for probe_attr, loss in avg_losses.items():\n",
    "        print(f\"{probe_attr} loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1ad6d10-0c1d-404f-b281-e855c0fffcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "probe_train_ds, probe_val_ds = load_data(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5c97700-047e-46e2-8903-f2f3463e8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Does nothing. Just for testing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device=\"cuda\", bs=64, n_steps=17, output_dim=256):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.bs = bs\n",
    "        self.n_steps = n_steps\n",
    "        self.repr_dim = 256\n",
    "\n",
    "    def forward(self, states, actions):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            states: [B, 1, Ch, H, W]\n",
    "            actions: [B, T-1, 2]\n",
    "\n",
    "        Output:\n",
    "            predictions: [B, T, D]\n",
    "        \"\"\"\n",
    "        return torch.randn((self.bs, self.n_steps, self.repr_dim)).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf38bba9-c61d-45de-9a90-a5433a303615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affc4ca0ca764db4b90542ab4a7d089b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probe prediction epochs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b107381615994628a653e1fa8adff85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probe prediction step:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 1.1027911901474\n",
      "normalized pred locations loss 0.986847460269928\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f64a5e04594aff9f79a2493e645421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Probe prediction step:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized pred locations loss 1.042397141456604\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m MockModel()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobe_train_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobe_val_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 10\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(device, model, probe_train_ds, probe_val_ds)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(device, model, probe_train_ds, probe_val_ds):\n\u001b[1;32m      2\u001b[0m     evaluator \u001b[38;5;241m=\u001b[39m ProbingEvaluator(\n\u001b[1;32m      3\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m      4\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m         quick_debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m     )\n\u001b[0;32m---> 10\u001b[0m     prober \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_pred_prober\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     avg_losses \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mevaluate_all(prober\u001b[38;5;241m=\u001b[39mprober)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m probe_attr, loss \u001b[38;5;129;01min\u001b[39;00m avg_losses\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/scratch/an3854/Chill-Pill/evaluator.py:112\u001b[0m, in \u001b[0;36mProbingEvaluator.train_pred_prober\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m Scheduler(\n\u001b[1;32m    102\u001b[0m     schedule\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mschedule,\n\u001b[1;32m    103\u001b[0m     base_lr\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlr,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbe prediction epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbe prediction step\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;66;03m# TODO: Forward pass through your model\u001b[39;00m\n\u001b[1;32m    115\u001b[0m         pred_encs \u001b[38;5;241m=\u001b[39m model(states\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mstates, actions\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mactions)\n\u001b[1;32m    116\u001b[0m         pred_encs \u001b[38;5;241m=\u001b[39m pred_encs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# # BS, T, D --> T, BS, D\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/an3854/aadim/lib64/python3.9/site-packages/tqdm/notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/an3854/aadim/lib64/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/an3854/aadim/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/scratch/an3854/aadim/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/an3854/aadim/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/an3854/aadim/lib64/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/an3854/Chill-Pill/dataset.py:32\u001b[0m, in \u001b[0;36mWallDataset.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[0;32m---> 32\u001b[0m     states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     actions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[i])\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MockModel().to(device)\n",
    "evaluate_model(device, model, probe_train_ds, probe_val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40d54a-78ef-4840-9214-61c422e9411f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aadim)",
   "language": "python",
   "name": "aadim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
